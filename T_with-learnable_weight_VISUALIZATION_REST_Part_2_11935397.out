wandb: Currently logged in as: piconda (drs). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /home/lcur2470/RS/wandb/run-20230623_170841-03rpvcfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run T-DiffRec_amazon-book_noisy_1_Visualization
wandb: â­ï¸ View project at https://wandb.ai/drs/drs
wandb: ğŸš€ View run at https://wandb.ai/drs/drs/runs/03rpvcfz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                    Epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–…â–…â–…
wandb:         batch_loss_train â–‡â–ˆâ–†â–ˆâ–‚â–ƒâ–‚â–„â–‚â–…â–ƒâ–„â–„â–„â–…â–„â–ƒâ–‚â–„â–ƒâ–…â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–‚â–„â–ƒâ–„â–‚â–…â–â–…
wandb:         best_test MRR@10 â–
wandb:        best_test MRR@100 â–
wandb:         best_test MRR@20 â–
wandb:         best_test MRR@50 â–
wandb:        best_test NDCG@10 â–
wandb:       best_test NDCG@100 â–
wandb:        best_test NDCG@20 â–
wandb:        best_test NDCG@50 â–
wandb:   best_test Precision@10 â–
wandb:  best_test Precision@100 â–
wandb:   best_test Precision@20 â–
wandb:   best_test Precision@50 â–
wandb:      best_test Recall@10 â–
wandb:     best_test Recall@100 â–
wandb:      best_test Recall@20 â–
wandb:      best_test Recall@50 â–
wandb:        best_valid MRR@10 â–
wandb:       best_valid MRR@100 â–
wandb:        best_valid MRR@20 â–
wandb:        best_valid MRR@50 â–
wandb:       best_valid NDCG@10 â–
wandb:      best_valid NDCG@100 â–
wandb:       best_valid NDCG@20 â–
wandb:       best_valid NDCG@50 â–
wandb:  best_valid Precision@10 â–
wandb: best_valid Precision@100 â–
wandb:  best_valid Precision@20 â–
wandb:  best_valid Precision@50 â–
wandb:     best_valid Recall@10 â–
wandb:    best_valid Recall@100 â–
wandb:     best_valid Recall@20 â–
wandb:     best_valid Recall@50 â–
wandb:    epoch_loss_norm_train â–ˆâ–†â–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–‚â–â–
wandb:              test MRR@10 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:             test MRR@100 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:              test MRR@20 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:              test MRR@50 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:             test NDCG@10 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:            test NDCG@100 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:             test NDCG@20 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:             test NDCG@50 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:        test Precision@10 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:       test Precision@100 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:        test Precision@20 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:        test Precision@50 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:           test Recall@10 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:          test Recall@100 â–ƒâ–‚â–„â–‡â–ˆâ–â–„â–†
wandb:           test Recall@20 â–ƒâ–‚â–„â–‡â–ˆâ–â–…â–†
wandb:           test Recall@50 â–ƒâ–‚â–„â–‡â–ˆâ–â–„â–†
wandb:             valid MRR@10 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:            valid MRR@100 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:             valid MRR@20 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:             valid MRR@50 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:            valid NDCG@10 â–„â–‚â–ƒâ–‡â–ˆâ–â–…â–…
wandb:           valid NDCG@100 â–„â–‚â–„â–‡â–ˆâ–â–„â–†
wandb:            valid NDCG@20 â–„â–‚â–„â–‡â–ˆâ–â–„â–†
wandb:            valid NDCG@50 â–„â–‚â–„â–‡â–ˆâ–â–„â–†
wandb:       valid Precision@10 â–„â–‚â–„â–‡â–ˆâ–â–…â–†
wandb:      valid Precision@100 â–„â–‚â–„â–‡â–ˆâ–â–„â–†
wandb:       valid Precision@20 â–„â–‚â–„â–‡â–ˆâ–â–„â–†
wandb:       valid Precision@50 â–„â–‚â–„â–‡â–ˆâ–â–„â–†
wandb:          valid Recall@10 â–„â–‚â–ƒâ–‡â–ˆâ–â–„â–…
wandb:         valid Recall@100 â–ƒâ–‚â–„â–‡â–ˆâ–â–„â–†
wandb:          valid Recall@20 â–ƒâ–‚â–„â–‡â–ˆâ–â–„â–†
wandb:          valid Recall@50 â–ƒâ–‚â–„â–‡â–ˆâ–â–„â–†
wandb: 
wandb: Run summary:
wandb:                    Epoch 25
wandb:         batch_loss_train 0.02261
wandb:         best_test MRR@10 0.0294
wandb:        best_test MRR@100 0.0332
wandb:         best_test MRR@20 0.0313
wandb:         best_test MRR@50 0.0327
wandb:        best_test NDCG@10 0.024
wandb:       best_test NDCG@100 0.0386
wandb:        best_test NDCG@20 0.0284
wandb:        best_test NDCG@50 0.034
wandb:   best_test Precision@10 0.0083
wandb:  best_test Precision@100 0.0026
wandb:   best_test Precision@20 0.0061
wandb:   best_test Precision@50 0.0038
wandb:      best_test Recall@10 0.0356
wandb:     best_test Recall@100 0.0931
wandb:      best_test Recall@20 0.0499
wandb:      best_test Recall@50 0.0716
wandb:        best_valid MRR@10 0.0193
wandb:       best_valid MRR@100 0.0228
wandb:        best_valid MRR@20 0.021
wandb:        best_valid MRR@50 0.0223
wandb:       best_valid NDCG@10 0.0131
wandb:      best_valid NDCG@100 0.023
wandb:       best_valid NDCG@20 0.0157
wandb:       best_valid NDCG@50 0.0197
wandb:  best_valid Precision@10 0.006
wandb: best_valid Precision@100 0.0023
wandb:  best_valid Precision@20 0.0047
wandb:  best_valid Precision@50 0.0032
wandb:     best_valid Recall@10 0.0185
wandb:    best_valid Recall@100 0.0559
wandb:     best_valid Recall@20 0.0273
wandb:     best_valid Recall@50 0.0418
wandb:    epoch_loss_norm_train 0.04019
wandb:              test MRR@10 0.0217
wandb:             test MRR@100 0.0245
wandb:              test MRR@20 0.023
wandb:              test MRR@50 0.0241
wandb:             test NDCG@10 0.0178
wandb:            test NDCG@100 0.0285
wandb:             test NDCG@20 0.0207
wandb:             test NDCG@50 0.025
wandb:        test Precision@10 0.0061
wandb:       test Precision@100 0.0019
wandb:        test Precision@20 0.0044
wandb:        test Precision@50 0.0028
wandb:           test Recall@10 0.026
wandb:          test Recall@100 0.0683
wandb:           test Recall@20 0.0358
wandb:           test Recall@50 0.0525
wandb:             valid MRR@10 0.013
wandb:            valid MRR@100 0.0157
wandb:             valid MRR@20 0.0143
wandb:             valid MRR@50 0.0153
wandb:            valid NDCG@10 0.0086
wandb:           valid NDCG@100 0.0159
wandb:            valid NDCG@20 0.0105
wandb:            valid NDCG@50 0.0135
wandb:       valid Precision@10 0.0041
wandb:      valid Precision@100 0.0017
wandb:       valid Precision@20 0.0033
wandb:       valid Precision@50 0.0023
wandb:          valid Recall@10 0.0121
wandb:         valid Recall@100 0.0393
wandb:          valid Recall@20 0.0184
wandb:          valid Recall@50 0.0294
wandb: 
wandb: ğŸš€ View run T-DiffRec_amazon-book_noisy_1_Visualization at: https://wandb.ai/drs/drs/runs/03rpvcfz
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230623_170841-03rpvcfz/logs
args: Namespace(batch_size=400, cuda=True, data_path='./datasets/', dataset='amazon-book_noisy', dims='[1000]', emb_size=10, epochs=1000, gpu='0', log_name='log', lr=0.0001, mean_type='x0_learnable', model_type='T-DiffRec', noise_max=0.02, noise_min=0.0001, noise_scale=0.1, noise_schedule='linear-var', norm=False, num_workers=0, patience=20, reweight=True, round=1, run_name='Visualization', sampling_noise=False, sampling_steps=0, save_path='./saved_models/', seed=1, steps=100, time_type='cat', topN='[10, 20, 50, 100]', tst_w_val=False, visualize_weights=False, w_max=1.0, w_min=0.1, weight_decay=0.0, workers=10)
Starting time:  2023-06-23 17:08:44
user num: 108822
item num: 178181
data ready.
Embedding size: 10
models ready.
Number of all parameters: 356552291
Start training...
Runing Epoch 001 train loss 12.3743 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 002 train loss 12.0488 costs 00: 01: 02
------------------------------------------------------
Runing Epoch 003 train loss 11.8799 costs 00: 01: 03
------------------------------------------------------
Runing Epoch 004 train loss 11.7760 costs 00: 01: 00
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0025
0.0019
0.0013
0.0009
 0.0072
0.0106
0.0161
0.0214
 0.0053
0.0063
0.0078
0.0091
 0.0085
0.0092
0.0098
0.01

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0032
0.0024
0.0015
0.001
 0.0135
0.0188
0.0272
0.035
 0.0092
0.0108
0.013
0.0147
 0.0117
0.0125
0.013
0.0132

Runing Epoch 005 train loss 11.4904 costs 00: 38: 45
------------------------------------------------------
Runing Epoch 006 train loss 11.5565 costs 00: 01: 02
------------------------------------------------------
Runing Epoch 007 train loss 11.3371 costs 00: 01: 01
------------------------------------------------------
Runing Epoch 008 train loss 11.2803 costs 00: 01: 04
------------------------------------------------------
Runing Epoch 009 train loss 11.2438 costs 00: 01: 02
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.001
0.0008
0.0005
0.0003
 0.0027
0.0039
0.0057
0.0074
 0.0021
0.0024
0.0029
0.0033
 0.0035
0.0038
0.004
0.004

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0014
0.001
0.0006
0.0004
 0.0055
0.0074
0.0101
0.0127
 0.004
0.0045
0.0053
0.0058
 0.0052
0.0055
0.0056
0.0057

Runing Epoch 010 train loss 11.1836 costs 00: 38: 45
------------------------------------------------------
Runing Epoch 011 train loss 11.2123 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 012 train loss 11.1823 costs 00: 01: 04
------------------------------------------------------
Runing Epoch 013 train loss 11.1373 costs 00: 01: 02
------------------------------------------------------
Runing Epoch 014 train loss 11.2331 costs 00: 01: 00
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0025
0.0021
0.0015
0.0011
 0.0071
0.0113
0.019
0.0263
 0.0051
0.0064
0.0084
0.0101
 0.0081
0.0089
0.0097
0.0099

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0036
0.0027
0.0018
0.0012
 0.0152
0.0216
0.0336
0.0444
 0.0102
0.0122
0.0152
0.0175
 0.0125
0.0134
0.0142
0.0145

Runing Epoch 015 train loss 11.2007 costs 00: 38: 46
------------------------------------------------------
Runing Epoch 016 train loss 11.0856 costs 00: 01: 04
------------------------------------------------------
Runing Epoch 017 train loss 10.9575 costs 00: 01: 01
------------------------------------------------------
Runing Epoch 018 train loss 10.9932 costs 00: 01: 01
------------------------------------------------------
Runing Epoch 019 train loss 11.0226 costs 00: 01: 00
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0052
0.0041
0.0028
0.002
 0.0161
0.0236
0.0368
0.0491
 0.0114
0.0137
0.0173
0.0202
 0.017
0.0185
0.0196
0.0201

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0073
0.0054
0.0035
0.0024
 0.0311
0.0441
0.065
0.0839
 0.0211
0.0251
0.0305
0.0346
 0.0258
0.0276
0.0289
0.0293

Runing Epoch 020 train loss 11.0337 costs 00: 38: 45
------------------------------------------------------
Runing Epoch 021 train loss 10.9916 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 022 train loss 10.9300 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 023 train loss 10.9208 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 024 train loss 10.9653 costs 00: 01: 01
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.006
0.0047
0.0032
0.0023
 0.0185
0.0273
0.0418
0.0559
 0.0131
0.0157
0.0197
0.023
 0.0193
0.021
0.0223
0.0228

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0083
0.0061
0.0038
0.0026
 0.0356
0.0499
0.0716
0.0931
 0.024
0.0284
0.034
0.0386
 0.0294
0.0313
0.0327
0.0332

Runing Epoch 025 train loss 10.9808 costs 00: 38: 54
------------------------------------------------------
Runing Epoch 026 train loss 10.9683 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 027 train loss 10.9921 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 028 train loss 11.0349 costs 00: 01: 02
------------------------------------------------------
Runing Epoch 029 train loss 11.0315 costs 00: 01: 00
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0004
0.0003
0.0002
0.0001
 0.0009
0.0014
0.0021
0.0029
 0.0007
0.0009
0.0011
0.0012
 0.0014
0.0015
0.0016
0.0017

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0004
0.0003
0.0002
0.0001
 0.0015
0.0022
0.0033
0.0042
 0.0011
0.0012
0.0015
0.0017
 0.0014
0.0015
0.0016
0.0017

Runing Epoch 030 train loss 10.9347 costs 00: 38: 42
------------------------------------------------------
Runing Epoch 031 train loss 11.1098 costs 00: 01: 04
------------------------------------------------------
Runing Epoch 032 train loss 10.9670 costs 00: 01: 04
------------------------------------------------------
Runing Epoch 033 train loss 11.0172 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 034 train loss 10.9940 costs 00: 01: 00
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0033
0.0025
0.0016
0.0011
 0.0096
0.0135
0.0197
0.0257
 0.0071
0.0082
0.0099
0.0114
 0.011
0.0118
0.0124
0.0126

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0048
0.0034
0.0021
0.0014
 0.0204
0.0272
0.0372
0.0461
 0.0145
0.0166
0.0193
0.0213
 0.0182
0.0192
0.0198
0.0201

Runing Epoch 035 train loss 10.9445 costs 00: 38: 45
------------------------------------------------------
Runing Epoch 036 train loss 11.1241 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 037 train loss 10.9671 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 038 train loss 10.9905 costs 00: 01: 00
------------------------------------------------------
Runing Epoch 039 train loss 10.9869 costs 00: 01: 00
------------------------------------------------------
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0041
0.0033
0.0023
0.0017
 0.0121
0.0184
0.0294
0.0393
 0.0086
0.0105
0.0135
0.0159
 0.013
0.0143
0.0153
0.0157

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0061
0.0044
0.0028
0.0019
 0.026
0.0358
0.0525
0.0683
 0.0178
0.0207
0.025
0.0285
 0.0217
0.023
0.0241
0.0245

Runing Epoch 040 train loss 10.9525 costs 00: 38: 41
------------------------------------------------------
Runing Epoch 041 train loss 11.1053 costs 00: 01: 03
------------------------------------------------------
Runing Epoch 042 train loss 10.9293 costs 00: 01: 04
------------------------------------------------------
Runing Epoch 043 train loss 11.0195 costs 00: 01: 01
------------------------------------------------------
Runing Epoch 044 train loss 10.9710 costs 00: 01: 00
------------------------------------------------------
------------------
Exiting from training early
======================================================
End. Best Epoch 025 
[Valid]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.006
0.0047
0.0032
0.0023
 0.0185
0.0273
0.0418
0.0559
 0.0131
0.0157
0.0197
0.023
 0.0193
0.021
0.0223
0.0228

[Test]: Precisions (4), Recalls (4), NDCGs (4), MRRs (4):

0.0083
0.0061
0.0038
0.0026
 0.0356
0.0499
0.0716
0.0931
 0.024
0.0284
0.034
0.0386
 0.0294
0.0313
0.0327
0.0332

End time:  2023-06-23 22:56:18
params_per_batch.shape: torch.Size([12007, 100, 10])
Saved params_per_batch.npy to mPHATE/T-DiffRec_amazon-book_noisy_1_Visualization_params_per_batch.npy
wandb: Currently logged in as: piconda (drs). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /home/lcur2470/RS/wandb/run-20230623_225632-9gnos4ds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run T-DiffRec_amazon-book_noisy_1_Visualization
wandb: â­ï¸ View project at https://wandb.ai/drs/drs
wandb: ğŸš€ View run at https://wandb.ai/drs/drs/runs/9gnos4ds
slurmstepd: error: *** JOB 11935397 ON r28n3 CANCELLED AT 2023-06-24T03:08:34 DUE TO TIME LIMIT ***
