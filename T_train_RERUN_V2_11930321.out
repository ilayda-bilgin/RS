args: Namespace(batch_size=400, cuda=True, data_path='./datasets/', dataset='yelp_noisy', dims='[1000]', emb_size=10, epochs=1000, gpu='1', log_name='log', lr=0.0001, mean_type='x0', model_type='T-DiffRec', noise_max=0.02, noise_min=0.0001, noise_scale=0.1, noise_schedule='linear-var', norm=False, num_workers=4, reweight=True, round=1, sampling_noise=False, save_path='./saved_models/', time_type='cat', topN='[10, 20, 50, 100]', tst_w_val=False, w_max=1.0, w_min=0.1, weight_decay=0.0)
args: Namespace(batch_size=400, cuda=True, data_path='./datasets/', dataset='yelp_noisy', dims='[1000]', emb_size=10, epochs=1000, gpu='1', log_name='log', lr=0.0001, mean_type='x0', model_type='T-DiffRec', noise_max=0.02, noise_min=0.0001, noise_scale=0.1, noise_schedule='linear-var', norm=False, num_workers=4, reweight=True, round=1, sampling_noise=False, sampling_steps=0, save_path='./saved_models/', steps=100, time_type='cat', topN='[10, 20, 50, 100]', tst_w_val=False, w_max=1.0, w_min=0.1, weight_decay=0.0)
Starting time:  2023-06-16 09:39:00
user num: 54574
item num: 77405
data ready.
models ready.
Number of all parameters: 154898515
Start training...
/home/lcur2470/.conda/envs/rs/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Runing Epoch 001 train loss 14.2782 costs 00: 00: 17
------------------------------------------------------
Runing Epoch 002 train loss 13.2466 costs 00: 00: 16
------------------------------------------------------
Runing Epoch 003 train loss 12.8632 costs 00: 00: 15
------------------------------------------------------
Runing Epoch 004 train loss 12.5752 costs 00: 00: 15
------------------------------------------------------
